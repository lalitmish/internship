{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d323fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\rb\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rb\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rb\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d669f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80230dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4279c12",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "\n",
    "1.First get the webpage https://www.naukri.com/ 2.Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field. 3.Then click the searchbutton. 4.Then scrape the data for the first 10 jobs results youget. 5.Finally create a dataframe of the scraped data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce5d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ebb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd1d7dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e528e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b232d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a14a3782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "        \n",
    "#scraping job location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "#scraping job experience from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e479ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a3c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6daff4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1995cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c54c975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tech Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Brunel</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Hitachi Energy</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Celonis &amp; Salesforce Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru</td>\n",
       "      <td>HARMAN</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Knowledge Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>SAP</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst (Bangalore)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Krazy Mantra</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Loyalytics Consulting</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Aventus Technology India</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Title  \\\n",
       "0                  Tech Data Analyst   \n",
       "1                       Data Analyst   \n",
       "2  Celonis & Salesforce Data Analyst   \n",
       "3  Celonis & Salesforce Data Analyst   \n",
       "4                       Data Analyst   \n",
       "5             Knowledge Data Analyst   \n",
       "6           Data Analyst (Bangalore)   \n",
       "7                       Data Analyst   \n",
       "8                       Data Analyst   \n",
       "9             Data Analyst - FinTech   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Hybrid - Bangalore/ Bengaluru, Karnataka, Gurg...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                       Bangalore/Bengaluru, Chennai   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                       Hybrid - Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "\n",
       "               Company_name Experience  \n",
       "0                     Wipro    3-6 Yrs  \n",
       "1                    Brunel    4-6 Yrs  \n",
       "2            Hitachi Energy    3-6 Yrs  \n",
       "3              Hitachi Ltd.    2-7 Yrs  \n",
       "4                    HARMAN    3-5 Yrs  \n",
       "5                       SAP    4-6 Yrs  \n",
       "6              Krazy Mantra   7-12 Yrs  \n",
       "7     Loyalytics Consulting    4-9 Yrs  \n",
       "8  Aventus Technology India    2-7 Yrs  \n",
       "9              Primo Hiring    1-2 Yrs  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889e055",
   "metadata": {},
   "source": [
    "# Q.2Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the \n",
    "location” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e686a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a156975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1eff00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25cf1d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c69e4ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0568c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "        \n",
    "#scraping job location from given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "#scraping job experience from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b953e0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29711248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(job_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "279397de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ba741bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0d6b068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permanent Opportunity - Data Scientist(Snaplog...</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ericsson India Global Services Pvt. Ltd.</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deputy Manager - B2C Underwriting</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Bajaj Finserv Ltd.</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...</td>\n",
       "      <td>Tata Consultancy Services (TCS)</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist - R/Python</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Permanent Opportunity - Data Scientist(Snaplog...   \n",
       "1                   Analystics & Modeling Specialist   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                  Deputy Manager - B2C Underwriting   \n",
       "6                          Hiring For Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                          Data Scientist - R/Python   \n",
       "9                  Data Scientist - Engine Algorithm   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Hybrid - Bangalore/ Bengaluru, Karnataka, Hyde...   \n",
       "7  Hybrid - Bangalore/Bengaluru, Pune, Delhi / NC...   \n",
       "8  Temp. WFH - Bangalore/Bengaluru, Kolkata, Mumb...   \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...   \n",
       "\n",
       "                               Company_name Experience  \n",
       "0                                  Deloitte   9-14 Yrs  \n",
       "1                                 Accenture    6-8 Yrs  \n",
       "2  Ericsson India Global Services Pvt. Ltd.    5-7 Yrs  \n",
       "3  Ericsson India Global Services Pvt. Ltd.    3-7 Yrs  \n",
       "4  Ericsson India Global Services Pvt. Ltd.    5-7 Yrs  \n",
       "5                        Bajaj Finserv Ltd.    1-3 Yrs  \n",
       "6           Tata Consultancy Services (TCS)    4-9 Yrs  \n",
       "7                                  Infogain    3-6 Yrs  \n",
       "8                            Okda Solutions    4-7 Yrs  \n",
       "9                              Primo Hiring    1-3 Yrs  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd0461",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below\n",
    "    You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get thewebpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the searchbutton.\n",
    "4. Then apply the location filter and salary filter by checking the respectiveboxes\n",
    "5. Then scrape the data for the first 10 jobs results youget.\n",
    "6. Finally create a dataframe of the scrapeddata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9039b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24271a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63daf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef68d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb9eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input\")\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fefcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5a2c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d52772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from given page\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "        \n",
    "#scraping job location from given page\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "#scraping company name from given page\n",
    "company_tags=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "    \n",
    "#scraping job experience from given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82146856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e0d2281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Permanent Opportunity - Data Scientist(Snaplog...</td>\n",
       "      <td>Hybrid - Delhi / NCR, Kolkata, Hyderabad/Secun...</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hybrid - Delhi / NCR, Pune, Bangalore/Bengalur...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - R/Python</td>\n",
       "      <td>Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Hyde...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - R/Python</td>\n",
       "      <td>Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Visa...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>IBS Software Services</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Director/Senior Director - Data Science</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>10-15 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Manager/Senior Manager - Data Science</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Axtria India</td>\n",
       "      <td>8-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Customer Facing Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Sparkbeyond</td>\n",
       "      <td>7-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Permanent Opportunity - Data Scientist(Snaplog...   \n",
       "1                    Machine Learning (AI) Architect   \n",
       "2                                     Data Scientist   \n",
       "3                          Data Scientist - R/Python   \n",
       "4                  Data Scientist - Engine Algorithm   \n",
       "5                          Data Scientist - R/Python   \n",
       "6                                     Data Scientist   \n",
       "7            Director/Senior Director - Data Science   \n",
       "8              Manager/Senior Manager - Data Science   \n",
       "9              Senior Customer Facing Data Scientist   \n",
       "\n",
       "                                            Location           Company_name  \\\n",
       "0  Hybrid - Delhi / NCR, Kolkata, Hyderabad/Secun...               Deloitte   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...             Persistent   \n",
       "2  Hybrid - Delhi / NCR, Pune, Bangalore/Bengalur...               Infogain   \n",
       "3  Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Hyde...         Okda Solutions   \n",
       "4  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...           Primo Hiring   \n",
       "5  Temp. WFH - Delhi / NCR, Kolkata, Mumbai, Visa...         Okda Solutions   \n",
       "6  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...  IBS Software Services   \n",
       "7  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...           Axtria India   \n",
       "8  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...           Axtria India   \n",
       "9  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...            Sparkbeyond   \n",
       "\n",
       "  Experience  \n",
       "0   9-14 Yrs  \n",
       "1   5-12 Yrs  \n",
       "2    3-6 Yrs  \n",
       "3    4-7 Yrs  \n",
       "4    1-3 Yrs  \n",
       "5    4-7 Yrs  \n",
       "6    3-8 Yrs  \n",
       "7  10-15 Yrs  \n",
       "8   8-12 Yrs  \n",
       "9    7-8 Yrs  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({'Title':job_title,'Location':job_location,'Company_name':company_name,'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3405b",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url :https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data asusual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page asusual\n",
    "6. Repeat this until you get data for 100sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d32388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6379afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3420d5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"715cbdb02fb6a174dbcb6338d1f4a74f\", element=\"A48DD79CFC1330CA9C75EF81F3CC4CF3_element_1\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_g= driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bed0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_g.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "293e8335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"715cbdb02fb6a174dbcb6338d1f4a74f\", element=\"A48DD79CFC1330CA9C75EF81F3CC4CF3_element_2\")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='L0Z3Pu']\")\n",
    "\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba235c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/search?q=Sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&as-pos=1&as-type=HISTORY%22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cdacd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "P_desc=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb3a3bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping page 1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "scraping page 2\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "scraping page 3\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "scraping page 4\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "#scraping job title from given page\n",
    "for i in range(4):\n",
    "    print('scraping page',i+1)\n",
    "    b_name=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "    for j in b_name:\n",
    "        brand=j.text\n",
    "        B_name.append(brand)\n",
    "        print(len(B_name))\n",
    "   \n",
    "    price_p=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for k in price_p:\n",
    "        price=k.text\n",
    "        Price.append(price)\n",
    "        print(len(Price))\n",
    "                              \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0846dd94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Br_name</th>\n",
       "      <th>P_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BKGE</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>style guru</td>\n",
       "      <td>₹899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Br_name P_price\n",
       "0   VINCENT CHASE    ₹688\n",
       "1   VINCENT CHASE    ₹749\n",
       "2       Elligator    ₹109\n",
       "3            BKGE    ₹149\n",
       "4        Fastrack    ₹499\n",
       "..            ...     ...\n",
       "95  VINCENT CHASE    ₹569\n",
       "96       Fastrack    ₹569\n",
       "97         PIRASO    ₹192\n",
       "98      Elligator    ₹213\n",
       "99     style guru    ₹899\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Br_name']=B_name\n",
    "sun_gl['P_price']=Price\n",
    "sun_gl.head(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b78256",
   "metadata": {},
   "source": [
    "Q.5 Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ffb2cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b39785ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0674f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85537378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#scraping job title from given page\n",
    "\n",
    "rating=driver.find_elements(By.XPATH,\"//div[@class='_2d4LTz']\")\n",
    "for j in rating[:100]:\n",
    "    Rating=j.text\n",
    "    rating.append(Rating)\n",
    "print(len(rating))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5aaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca3b96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bb05f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "823cdcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.jagranjosh.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c88150b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"4319572aef00c3789855f48a8a59c83a\", element=\"5407E0890438628CFFCA1076176828D0_element_2\")>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_g= driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bbf5916",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=113.0.5672.129)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EE8893+48451]\n\t(No symbol) [0x00E7B8A1]\n\t(No symbol) [0x00D84F20]\n\t(No symbol) [0x00DACB96]\n\t(No symbol) [0x00DAC401]\n\t(No symbol) [0x00DCA2BC]\n\t(No symbol) [0x00DA9586]\n\t(No symbol) [0x00DCA614]\n\t(No symbol) [0x00DDC482]\n\t(No symbol) [0x00DCA0B6]\n\t(No symbol) [0x00DA7E08]\n\t(No symbol) [0x00DA8F2D]\n\tGetHandleVerifier [0x01148E3A+2540266]\n\tGetHandleVerifier [0x01188959+2801161]\n\tGetHandleVerifier [0x0118295C+2776588]\n\tGetHandleVerifier [0x00F72280+612144]\n\t(No symbol) [0x00E84F6C]\n\t(No symbol) [0x00E811D8]\n\t(No symbol) [0x00E812BB]\n\t(No symbol) [0x00E74857]\n\tBaseThreadInitThunk [0x762000C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77677B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77677B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msearch_g\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGK\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    228\u001b[0m             remote_files\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload(file))\n\u001b[0;32m    229\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(remote_files)\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSEND_KEYS_TO_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys_to_typing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:403\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    401\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    402\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=113.0.5672.129)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EE8893+48451]\n\t(No symbol) [0x00E7B8A1]\n\t(No symbol) [0x00D84F20]\n\t(No symbol) [0x00DACB96]\n\t(No symbol) [0x00DAC401]\n\t(No symbol) [0x00DCA2BC]\n\t(No symbol) [0x00DA9586]\n\t(No symbol) [0x00DCA614]\n\t(No symbol) [0x00DDC482]\n\t(No symbol) [0x00DCA0B6]\n\t(No symbol) [0x00DA7E08]\n\t(No symbol) [0x00DA8F2D]\n\tGetHandleVerifier [0x01148E3A+2540266]\n\tGetHandleVerifier [0x01188959+2801161]\n\tGetHandleVerifier [0x0118295C+2776588]\n\tGetHandleVerifier [0x00F72280+612144]\n\t(No symbol) [0x00E84F6C]\n\t(No symbol) [0x00E811D8]\n\t(No symbol) [0x00E812BB]\n\t(No symbol) [0x00E74857]\n\tBaseThreadInitThunk [0x762000C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77677B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77677B1E+238]\n"
     ]
    }
   ],
   "source": [
    "search_g.send_keys('GK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b75d262",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to type in the search bar ’50 most expensive cars’\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5611ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9022ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd17bf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\RB\\Desktop\\flip robo internship\\New folder\\chrome driver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19337a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the webpage\n",
    "driver.get(\"https://www.motor1.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b148fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"f9f04183293aa35e7de778c0f7b8913b\", element=\"481B1C3E17FAF967E84F4E56DE79B798_element_35\")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_g= driver.find_element(By.XPATH,\"//input[@type='text']\")\n",
    "\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66ecaa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_g.send_keys('50 most expensive cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68273eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@class='features-search_input']\"}\n  (Session info: chrome=113.0.5672.129)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EE8893+48451]\n\t(No symbol) [0x00E7B8A1]\n\t(No symbol) [0x00D85058]\n\t(No symbol) [0x00DB0467]\n\t(No symbol) [0x00DB069B]\n\t(No symbol) [0x00DDDD92]\n\t(No symbol) [0x00DCA304]\n\t(No symbol) [0x00DDC482]\n\t(No symbol) [0x00DCA0B6]\n\t(No symbol) [0x00DA7E08]\n\t(No symbol) [0x00DA8F2D]\n\tGetHandleVerifier [0x01148E3A+2540266]\n\tGetHandleVerifier [0x01188959+2801161]\n\tGetHandleVerifier [0x0118295C+2776588]\n\tGetHandleVerifier [0x00F72280+612144]\n\t(No symbol) [0x00E84F6C]\n\t(No symbol) [0x00E811D8]\n\t(No symbol) [0x00E812BB]\n\t(No symbol) [0x00E74857]\n\tBaseThreadInitThunk [0x762000C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77677B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77677B1E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m search_btn\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//input[@class=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures-search_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m search_btn\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:831\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    828\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    829\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    438\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    243\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//input[@class='features-search_input']\"}\n  (Session info: chrome=113.0.5672.129)\nStacktrace:\nBacktrace:\n\tGetHandleVerifier [0x00EE8893+48451]\n\t(No symbol) [0x00E7B8A1]\n\t(No symbol) [0x00D85058]\n\t(No symbol) [0x00DB0467]\n\t(No symbol) [0x00DB069B]\n\t(No symbol) [0x00DDDD92]\n\t(No symbol) [0x00DCA304]\n\t(No symbol) [0x00DDC482]\n\t(No symbol) [0x00DCA0B6]\n\t(No symbol) [0x00DA7E08]\n\t(No symbol) [0x00DA8F2D]\n\tGetHandleVerifier [0x01148E3A+2540266]\n\tGetHandleVerifier [0x01188959+2801161]\n\tGetHandleVerifier [0x0118295C+2776588]\n\tGetHandleVerifier [0x00F72280+612144]\n\t(No symbol) [0x00E84F6C]\n\t(No symbol) [0x00E811D8]\n\t(No symbol) [0x00E812BB]\n\t(No symbol) [0x00E74857]\n\tBaseThreadInitThunk [0x762000C9+25]\n\tRtlGetAppContainerNamedObjectPath [0x77677B4E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77677B1E+238]\n"
     ]
    }
   ],
   "source": [
    "search_btn=driver.find_element(By.XPATH,\"//input[@class='features-search_input']\")\n",
    "\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b085ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Scrape the data and create the dataframe\n",
    "car_list = []\n",
    "prices_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "288cf3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_list=driver.find_elements(By.XPATH,\"//h3[@class='subheader']\")\n",
    "for j in c_list:\n",
    "    list=j.text        \n",
    "    car_list.append(list)        \n",
    "    print(len(car_list))\n",
    "\n",
    "price_p=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "for k in price_p:\n",
    "    price=k.text\n",
    "    prices_list.append(price)        \n",
    "    print(len(prices_list))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc3a569a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Car Name, Price]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Car Name': car_list, 'Price': prices_list})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcf036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b179092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
